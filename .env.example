# ============================================
# AI Logo Generator - Environment Configuration
# For GPU-based Flux Model Inference on Vast.ai
# ============================================

# ----------------
# Server Settings
# ----------------
PORT=7860
HOST=0.0.0.0
ENVIRONMENT=production

# ----------------
# Model Configuration
# ----------------
# HuggingFace model name (will be downloaded on first run)
MODEL_NAME=black-forest-labs/FLUX.1-dev

# OR use local model path (if you have pre-downloaded the model)
# MODEL_PATH=/app/models/flux-dev

# Use FP16 precision for faster inference and lower memory usage
USE_FP16=true

# ----------------
# GPU Configuration
# ----------------
TORCH_DEVICE=cuda
ENABLE_ATTENTION_SLICING=true
ENABLE_VAE_SLICING=true

# ----------------
# Inference Settings
# ----------------
# Maximum number of concurrent inference jobs (adjust based on GPU memory)
MAX_CONCURRENT_JOBS=2

# Request timeout in seconds
REQUEST_TIMEOUT=300

# Default inference parameters
DEFAULT_INFERENCE_STEPS=28
DEFAULT_GUIDANCE_SCALE=3.5

# ----------------
# Warmup Configuration
# ----------------
# Enable GPU warmup on startup (recommended)
WARMUP_ENABLED=true
WARMUP_PROMPT=test logo
WARMUP_SIZE=256
WARMUP_STEPS=4

# ----------------
# Logging Configuration
# ----------------
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: json (for production) or text (for development)
LOG_FORMAT=json

# ----------------
# HuggingFace Token (Optional)
# ----------------
# Only needed if downloading gated models
# Get your token from: https://huggingface.co/settings/tokens
# HF_TOKEN=your_huggingface_token_here

